# PTI preparation {#pti-prep}

The next step in the PTI process is to create a PTI dashboard. This dashboard primarily serves two purposes: 1) a one-stop shop that offers a wide range of subnational indicators readily available and accessible; and 2) a user-friendly tool to make the calculation of a PTI easy, flexible and adaptable. There are already a number of countries where the dashboard is already up and running. This section walks you through how to build a PTI dashboard from scratch. All the baseline infrastructure that goes into the construction of a PTI dashboard is prepared in R so please skip the rest of this section if you are not responsible for writing R scripts to prepare data and launch the PTI dashboard. 

## Setup: Data cleaning
The first thing that you need to do is to prepare data that goes into a PTI dashboard. We typically create a new folder called xxxPTIdata (where xxx is ISO-3 country code, e.g., moz for Mozambique) to manage scripts for cleaning and merging data. Here is a recommended folder structure for xxxPTIdata: 

    +-- data-clean
    |   \-- metadata/metadata.xlsx
    +-- data-raw
    +-- dev
    +-- vignettes
    +-- xxxPTIdata.Rproj
    +-- .gitignore

where `data-clean` contains clean data ready to be merged; `data-raw` all raw datasets; `dev` functions used to clean and visualize data; and `vignettes` R scripts to clean data. You can find a concrete example for [Zambia PTI work]( https://github.com/wbPTI/zamPTIdata).^[The [`zamPTIdata`]( https://github.com/wbPTI/zamPTIdata) repo is a private repository so you need to request access. Please [contact Taka Masaki](mailto:tmasaki@worldbank.org).] Please note that `data-clean/metadata/metadata.xlsx` should contain the description of all indicators to be included in the dashboard. We will come back to this topic in [Section 3.1.2](#metadata).

In the following sections, we will walk you through several key steps that need to be followed to prepare a dataset using the [Zambia PTI dashboard](https://wbg-poverty-gp.shinyapps.io/zamPTI/) and the [`zamPTIdata`]( https://github.com/wbPTI/zamPTIdata) repo as an example. 

The scripts to turn raw data into clean data are all stored in the `vignettes` folder and make sure that these scripts are numbered in order of how they should be sequentially run to produce all the clean datasets needed at the end. And clean data should all be saved in the `RDS` format in the `data-clean` folder and ensure that *all* baseline shapefiles are included in each of the clean data file. See how the `data-clean` folder should look like again in the example of the [`zamPTIdata`]( https://github.com/wbPTI/zamPTIdata) repo. 


### Getting shapefiles ready

The PTI dashboard will allow users to see a wide range of subnational indicators at varying levels of geographical disaggregation. The first thing that you need to do is to create a `RDS` file that contains a list of shapefiles, which will be used for compiling all indicators down the road and then displayed in the dashboard. This `RDS` file would look like this:

```{r setup_lib, include=FALSE}
#knitr::opts_chunk$set(fig.width = 12, 
#                      fig.height = 5,
                      # fig.asp = 3/4,
                      # out.width = "60%",
                      # fig.align = "center",
                      # dpi = 150,
#                      message = FALSE,
#                      echo = FALSE,
#                    warning = FALSE,
#                      error = FALSE,
#                      cache = FALSE
#                      )

# Packages
conflictRules("tidyr", mask.ok = c("extract"))
conflictRules("dplyr", mask.ok = c("filter", "lag", "select"))
pacman::p_load(readxl,here,dplyr,sf,readr)
```

```{r, echo=TRUE,comment=TRUE}
#set your own path
shp <- readRDS(here("..","zamPTIdata","data-clean","app-shapes","Zambia.rds")) 

knitr::kable(
  head(shp$admin0_Country, 10), longtable = TRUE, booktabs = TRUE,
  caption = 'ADM0 level')

knitr::kable(
  head(shp$admin1_Provinces, 10), longtable = TRUE, booktabs = TRUE,
  caption = 'ADM1 level')

knitr::kable(
  head(shp$admin2_Districts, 10), longtable = TRUE, booktabs = TRUE,
  caption = 'ADM2 level')

knitr::kable(
  head(shp$admin4_Wards, 10), longtable = TRUE, booktabs = TRUE,
  caption = 'ADM4 level')

```

In this specific case, there are four levels of shapefiles contained within this `list` object: ADM0 (country); ADM1 (Province); ADM2 (District); and ADM4 (Wards). We selected these four different levels of geographical aggregation for Zambia PTI because most indicators that we have for the country are available only at these levels.^[Of course, if you want to add more layers, you are free to do so but the number of layers you may wan to have in the dashboard depends on need and demand of your intended users.] 

When you create this `RDS` file, it is critical that you have the following attributes:

- This `RDS` file should contain a `list` object of all layers of shapefiles (e.g., ADM0, ADM1, ADM2, and so on). Each shapefile contained in the `list` object should have the following indicators:
  - `admin\*Pcod`: a location ID (which typically comes with the original shapefile you download online or obtain from colleagues but you can also create your own ID if you like)
  - `admin\*Name`: the name of a location
  - `area`: the size of area. This should be computed after properly reprojecting the shapefile in the appropriate EPSG UTM so that the area is expressed in km^2.  
- For those shapefiles at ADM`x` where `x`<`y` and `y` is the highest level of geographcial aggregation (which is almost always admin 0), make sure to include all the `admin\*Pcod` from shapefiles at admin `z` > `x` so that the final `RDS` file can make a link across different levels of geographical data using `admin\*Pcod`. For example, the shapefile of ADM1 should contain admin0Pcod from the shapefile of ADM0 and the shapefile of ADM2 should contain admin0Pcod and admin1Pcod from the shapefiles of ADM0 and ADM1, and so on. 
- Make sure to include ADM0 shapefile. Otherwise the R package used to launch a PTI dashboard will not run.

With all these points in mind, let's create a `RDS` file that contains an `list` object containing all levels of shapefiles. Below is just a sample code from the zamPTIdata repo:

```{r, echo=TRUE,comment=TRUE,eval=FALSE}
##read ADM1 shapefile
admin1 <- sf::st_read(here("data-raw","admin-boundaries","grid3-zam-admin","shapefiles","admin1_provinces.shp"))

##generate ADM0 shapefile from ADM1 shapefile 
admin0 <- admin1 %>%
  mutate(admin0Pcod = "ZM",
         admin0Name = "Zambia") %>%
  group_by(admin0Pcod, admin0Name) %>% 
  summarise(area = sum(area)) %>% 
  ungroup() %>% 
  st_make_valid()

##read ADM2 shapefile
admin2 <- sf::st_read(here("data-raw","admin-boundaries","grid3-zam-admin","shapefiles","admin2_districts.shp"))

##read ADM4 shapefile
admin4 <- sf::st_read(here("data-raw","admin-boundaries","grid3-zam-admin","shapefiles","admin4_wards.shp"))

##combine all levels
zam_bnd <- list()
zam_bnd$admin0_Country <- admin0
zam_bnd$admin1_Provinces <- admin0
zam_bnd$admin2_Districts <- admin2
zam_bnd$admin4_Wards <- admin4

##now save this baseline shapefile data in RDS file. 
#zam_bnd %>% readr::write_rds(here("data-clean","app-shapes","Zambia.rds"), compress = "gz")

```

Once you create the baseline `RDS` file that contains all levels of administrative boundary shapefiles, save it in the `data-clean` folder. 

### Generate indicators
Once you have the baseline shapefile data and stored it in the `data-clean` folder, you can start generating and integrating indicators. As mentioned earlier in [Chapter 2](#identification), a set of indicators that goes into the PTI dashboard depends on the objectives of a PTI dashboard. This means that there is no one-size-fits-all guideline on how to create these indicators. That said, there are a common set of routine data operations that we typically form for all PTI dashboards. In the following subsections, we discuss some of these operations and some sample R scripts to perform them. 

### Computing zonal statistics
One common data operation that we perform is to compute zonal statistics based on raster data. Let's say we want to compute the sum or mean of gridded raster population data from [WorldPop](https://www.worldpop.org/) at each level of geographical disaggregation. The [`exactextractr` ](https://cran.r-project.org/web/packages/exactextractr/index.html) package and `purrr::map` are very useful for this purpose.^[The utility of using `purrr::map` instead of `for` loop is explained [here](https://rpubs.com/christianthieme/589762).] See [`vignettes/06.population-high-res-data.R`]( https://github.com/wbPTI/zamPTIdata/blob/main/vignettes/06-population-high-res-data.R) from the [`zamPTIdata`]( https://github.com/wbPTI/zamPTIdata) repo as an example. 

It is always suggested that zonal statistics generated based on raster data are computed at *all* levels of shapefiles. The reason is that when the dashboard is launched, these data can be displayed at different levels of aggregation if they are prepared for each level of shapefile.

### Manually matching location names
You may need to manually match location names to the baseline shapefiles if the input data that you are trying to integrate do not already have unique location IDs or names that match perfectly with the respective shapefile. In such instances, make sure that you prepare a spreadsheet (either in Excel, CSV, or other format alike) that matches the location names between your input data and shapefile. See [`vignettes/07-zamstat-population-district.R`]( https://github.com/wbPTI/zamPTIdata/blob/main/vignettes/07-zamstat-population-district.R), which matches a dataset on the district-level population from the population census with the district-level shapefile using a cross-over table `data-raw/population-data/cso/cso-pop-2020-voters.xlsx`.

### Common indicators to be included
#### Human capital and health
Human capital and health indicators are almost always included in the PTI dashboard given that they often serve as one of the key criteria for geographical targeting. These indicators are commonly derived from Demographic Health Survey (DHS), household budget survey (HBS), Multiple Indicator Cluster Surveys (MICS), population census among others. As for DHS, there is a nice [website](https://www.statcompiler.com/en/) where you can easily download the indicators of your interest and match them with administrative boundary shapefiles, which also are available from the DHS geospatial [portal](https://spatialdata.dhsprogram.com/home/). 

#### Accessibility
Another common set of indicators that we typically generate includes measures of accessibility. Two common usedly indices include the Market Access Index (MAI)^[While there are many different measures of market access, one that we typically use is from [@JedwabStoreygard_2021].] and the Rural Access Index (RAI).^[See, for instance, [@Iimi_etal_2016] and https://rai.azavea.com/]. Since these indicators are included in almost all PTI dashboards, we created a R package specifically for this purpose. Please refer to [the `devaccess` package]( https://github.com/wbPTI/devaccess). In the package [website]( https://github.com/wbPTI/devaccess), you find concrete examples walking you through how these indices can be constructed based on publicly available data. You can also see how the MAI was calculated for Zambia in [`vignettes/13-mai.R`]( https://github.com/wbPTI/zamPTIdata/blob/main/vignettes/13-mai.R).

#### Natural disaster and conflict risks
Another set of indicators that are commonly included in a PTI dashboard seeks to measure natural disaster and fragility risks. We also generated routine functions that are now summarized in the [`devdisaster`]( https://github.com/wbPTI/devdisaster) package. This package allows you to compute various measures of natural disaster and fragility risks. See the package [website]( https://github.com/wbPTI/devdisaster) for more details.

## Setup: Launching a dashboard
Now that you have clean data ready to be merged in the `data-clean` folder, it is time to prepare a dashboard. The way we do this is through `r-shiny`. There are many tutorials on `r-shiny` and if you are unfamiliar with it, we highly recommend that you take one of these tutorials. The most basic tutorial is available from [here](https://shiny.rstudio.com/tutorial/). 

That said, you do not necessarily need to know nuts and bolts about `r-shiny` to launch a PTI dashboard. Because we routinely create a PTI dashboard with the same layout and functionalities for many different countries, we have created a R package specifically for this purpose: [`devPTIpack`](https://github.com/wbPTI/devPTIpack). The package [website](https://github.com/wbPTI/devPTIpack) offers a wide range of functions beyond just simply greating a dashboard so if you are interested in digging deeper, please refer to the package website. In this guideline, we will basically cover minimum steps required to launch an app using the package. 

### Install the `devPTIpack` package

The first thing you need to do is to create a folder specifically for your dashboard. This folder needs to follow a certain structure. You can create it by using `create_new_pti()` in the `devPTIpack` package.  For instance, if you want to create a dashboard for country xxx, you will run the following codes:

```{r pti_setup, echo=TRUE,comment=TRUE,eval=FALSE}
# Install development version from GitHub
remotes::install_github("wbPTI/devPTIpack")

#devPTIpack::create_new_pti("PATH-TO-NEW-PROJECT-LOCATION/PROJECT-NAME")

#-   `PATH-TO-NEW-PROJECT-LOCATION` is a relative or an absolute path to the folder, where the app should be created.

#-   a new sub-folder with the app itself will be created with the name `PROJECT-NAME`.
    
##For instance, you can specify a path as follows:
devPTIpack::create_new_pti("C:/Users/WB495141/GitHub/xxxPTI")
```

This sample script will create a new folder called `xxxPTI` in this directory `C:/Users/WB495141/GitHub`. In it, you find the following file structure:

    +-- app-data
    |   \-- metadata.Rmd
    +-- app.R
    +-- xxxPTI.Rproj
    +-- landing-page.md
    \-- R
    |   \-- _disable_autoload.R

We will explain what each file does in this new folder in the following sections. 

### Create a metadata {#metadata}
Now that all your datasets are cleaned and ready to be merged, you can use `xxxPTIdata/vignettes/100-compilation.Rmd`^[You can simply copy this `Rmd` file from the [`zamPTIdata`]( https://github.com/wbPTI/zamPTIdata) repo. See, for example, a sample [code]( https://github.com/wbPTI/zamPTIdata/blob/main/vignettes/100-compilation.Rmd) from the zamPTIdata repository.] to compile all datasets, create a metadata, which contains both the descriptions of all the indicators as well as the data to be displayed in the dashboard, and save the list data of all the administrative boundary shapefiles `admin_bounds.rds` in the `xxxPTI/app-data` folder.

The metadata will contain the following sheets:

- `general`: contains country name (e.g., Zambia, Tanzania, Kenya)
- `metadata`: includes the following variables:
  - `var_code`: variable name in the dataset
  - `var_name`: variable name as it appears in the dashboard. **DO NOT USE ":" in variable name because it can break the app compliation in devPTIpack.**
  - `var_order`: number indicating the order in which variables appear in the dashboard. Variables are sorted by pillar_group and var_order.	
  - `spatial_level`: the most granular level of disaggregation where a given variable is available in the data. For instance, if an indicator is available at ADM1 and ADM2, you should indicate ADM2 in this column. For instance, in the case of Zambia, this column should state `admin2_Districts` for those indicators available at ADM2 and `admin1_Provinces` for those available at ADM1. 
  - `var_description`: detailed description of a given variable indicating how it's constructed and sources from which the variable is derived.
  - `var_units`: unit of a variable (e.g., km, tonnes, minutes, USD) (optional)	
  - `pillar_group`: numeric code used to group pillar
  - `pillar_name`: pillar name. **DO NOT USE ":" in pillar name because it can break the app compliation in devPTIpack.**
  - `pillar_description`: detailed description of a pillar (optional)
  - `fltr_exclude_pti`: TRUE if you want to exclude a given variable from the PTI tab in the dashboard; FALSE otherwise
  - `fltr_exclude_explorer`: TRUE if you want to exclude a given variable from the Data Explorer tab in the dashboard
  - `fltr_overlay_pti`: Set it all FALSE.
  - `fltr_overlay_explorer`: Set it all FALSE
  - `legend_revert_colours`: TRUE if you want to reverse the legend color for a given variable; FALSE otherwise. 
- `point_data`: Do not change. It's just a placeholder.
- `weights_table`: Do not change. It's just a placeholder.
- `admin`##`LOCATION`: data at the `LOCATION` level (or ADM \##\), which will be displayed in the dashboard. 

Note that the `metadata` sheet in the metadata generated in `xxxPTIdata/vignettes/100-compilation.Rmd` comes from `xxxPTIdata/data-clean/metadata/metadata.xlsx`. You need to manually edit this file `xxxPTIdata/data-clean/metadata/metadata.xlsx` to ensure that all indicators that you would like to have in the dashboard are included and described well in `xxxPTIdata/data-clean/metadata/metadata.xlsx`. When creating this metadata file, **make sure that you should provide a description of a variable that is as thorough as possible.** It should explain how a given indicator is constructed and what sources are used with as much details that you can provide as possible. See `zamPTIdata/data-clean/metadata/metadata.xlsx` as an example.

Once all manual edits are made in `xxxPTIdata/data-clean/metadata/metadata.xlsx`, you can then run `xxxPTIdata/vignettes/100-compilation.Rmd` to compile the datasets and produce a metadata. Please note that you need to also manually edit `xxxPTIdata/vignettes/100-compilation.Rmd` to properly compile all datasets. This will leave you with a new metadata `mtdt-TIME.xlsx` and `admin_bounds.rds` created in the `xxxPTI/app-data` folder where TIME is the date and time of when the metadata is generated. 

### Generate a PDF document of a metadata {#metadata_pdf}
Once your metadata and `admin_bounds.rds` are both exported into the `xxxPTI/app-data` folder, run `xxxPTI/app-data/metadata.Rmd` to generate a PDF version of the metadata `metadata.pdf`, which will be made available and downloadable from the dashboard.

### Edit contents in the landing page of the dashboard {#landing_page}
What's in `landing-page.md` gets displayed as a landing page for the dashboard. Customize the content for your purpose. See a concrete example from [`zamPTI/landing-page.md`]( https://github.com/wbPTI/zamPTI/blob/main/landing-page.md). 

### Prepare zip folder that contains all levels of shapefiles for download
To make the baseline shapefiles also available for users, zip all the shapefiles and save them in the `app-data` folder. 


### Launch an app
Now you are ready to launch an app. Before that, you make sure that you've gotten all the ingriedients you would need to launch an app. The final `xxxPTI` folder should look like this:

    +-- app-data
    |   +-- admin_bounds.rds
    |   +-- metadata.pdf
    |   +-- metadata.Rmd
    |   +-- mtdt.xlsx
    |   \-- shapefiles.rar
    +-- app.R
    +-- xxxPTIapp.Rproj
    +-- landing-page.md
    \-- R
        \-- _disable_autoload.R

where

- `app-data/admin_bounds.rds`: a list object of all administrative boundary shapefiles (see )
- `app-data/metadata.pdf`: PDF document of metadata (see)
- `app-data/mtdt.xlsx`: metadata
- `app-data/shapefiles.rar`: zipped folder containing all shapefiles for download
- `app.R`: R script to launch an app
- `xxxPTIapp.Proj`: proj file for the app
- `landing-page.md`: content of the landing page of the dashboard

The `app.R` script launches the app and could be used to deploy
such app to an external server. Modify this to read all the inputs pertaining to your own `xxxPTI` folder:

    # Launch the ShinyApp (Do not remove this comment)
    # To deploy, run: rsconnect::deployApp()
    # Or use the blue button on top of this file

    library(shiny)
    library(devPTIpack)

    launch_pti(
      shp_dta = readRDS("app-data/admin_bounds.rds"),
      inp_dta = devPTIpack::fct_template_reader("app-data/mtdt.xlsx"),
      app_name = "Example country", 
      show_waiter = TRUE, 
      show_adm_levels = c("admin2"), 
      shapes_path = "app-data/shapefiles.zip", 
      mtdtpdf_path = "app-data/metadata.pdf",
      pti_landing_page = "./landing-page.md"
    )

While the way you specify each option in the `launch_pti()` function should be relatively straightforward, it is worth paying particular attention to `show_adm_levels`. This is where you specify at what level(s) of geographical disaggregation PTIs will be computed in the dashboard. Let's say you want users to calculate PTI only at the ADM2 level, you can specify `show_adm_levels=c("admin2")`. If you want to allow users to calculate PTI at both ADM2 and ADM4 levels, you then can specifiy `show_adm_levels=c("admin2","admin4")` and so on. Although you can choose whatever level you want users to calculate the PTI, it's recommended that you want to simplify this as much as possible so that users won't be overwhelmed by the information presented in the dashboard. One way to simplify is to just specifiy this at the lowest level of geographical disaggregation that the data allows for. 

That's it! Hope you now see a beautiful dashboard show up on your screen. 
